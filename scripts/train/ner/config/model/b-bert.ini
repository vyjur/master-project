[GENERAL]
name="model-ner-b"

[MODEL]
name=TokenBERT
load=false
lexicon=false
schema=BIO

[pretrain]
name=ltg/norbert3-small

[train.parameters]
train_batch_size=32
valid_batch_size=32
epochs=100
learning_rate=0.0001
optimizer=adam
weight_decay=1e-05
early_stopping_patience=3
early_stopping_delta=0.001
embedding_dim=32
max_length=512
stride=0
weights=false
shuffle=true
num_workers=0

[tuning]
tune=true
count=30
