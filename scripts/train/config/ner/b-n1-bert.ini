[GENERAL]
name="ner-b-n1"

[MODEL]
name=TokenBERT
load=false
max_length=128
lexicon=false

[pretrain]
name=norallm/normistral-11b-warm

[train.parameters]
train_batch_size=32
valid_batch_size=16
epochs=10
learning_rate=1e-2
shuffle=true
num_workers=0
