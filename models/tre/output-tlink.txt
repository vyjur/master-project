Spawning shell within /cluster/home/julievt/.cache/pypoetry/virtualenvs/master-project-118ajfdt-py3.12
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: master-project (0.1.0)
##### Start training for TRE... ######
### Processing the files:
###### (0) Training for configuration file: c-bert-bilstm.ini
LOAD False
Using: cuda:0 with NN
{'OVERLAP': 11844, 'BEFORE': 3137, 'O': 3555}
{'OVERLAP': 0.5216706067769897, 'BEFORE': 1.9696100308150037, 'O': 1.7380215658696672}
{'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'valid_batch_size': 16, 'optimizer': 'adam', 'weight_decay': 0.0001, 'early_stopping_patience': 5, 'early_stopping_delta': 0.01, 'embedding_dim': 300, 'max_length': 128, 'shuffle': True, 'num_workers': 0, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'logging_strategy': 'epoch', 'tune': False}
Epoch 1
-------------------------------
Batch 0, Loss: 1.178288221359253
Batch 100, Loss: 0.775550365447998
Batch 200, Loss: 0.8061993718147278
Batch 300, Loss: 0.847101092338562
Epoch 2
-------------------------------
Batch 0, Loss: 0.8286071419715881
Batch 100, Loss: 0.750214695930481
Batch 200, Loss: 0.8954842686653137
Batch 300, Loss: 0.7068377733230591
Epoch 3
-------------------------------
Batch 0, Loss: 0.7349265217781067
Batch 100, Loss: 0.666050374507904
Batch 200, Loss: 0.8856104612350464
Batch 300, Loss: 0.5794578790664673
Epoch 4
-------------------------------
Batch 0, Loss: 0.7697460651397705
Batch 100, Loss: 0.6557737588882446
Batch 200, Loss: 0.7263332605361938
Batch 300, Loss: 0.7446919679641724
Epoch 5
-------------------------------
Batch 0, Loss: 1.1742671728134155
Batch 100, Loss: 0.6322485208511353
Batch 200, Loss: 0.7738725543022156
Batch 300, Loss: 0.9538766145706177
Epoch 6
-------------------------------
Batch 0, Loss: 0.7363516092300415
Batch 100, Loss: 0.6236037611961365
Batch 200, Loss: 0.787293553352356
Batch 300, Loss: 0.5701856017112732
Early stopping
### Valid set performance:
Validation Accuracy: 0.6446392447741065
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       477
           O       0.00      0.00      0.00       577
     OVERLAP       0.64      1.00      0.78      1912

    accuracy                           0.64      2966
   macro avg       0.21      0.33      0.26      2966
weighted avg       0.42      0.64      0.51      2966

### Test set performance:
Validation Accuracy: 0.6475188781014024
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       626
           O       0.00      0.00      0.00       681
     OVERLAP       0.65      1.00      0.79      2401

    accuracy                           0.65      3708
   macro avg       0.22      0.33      0.26      3708
weighted avg       0.42      0.65      0.51      3708

### Inter sentences performance:
Validation Accuracy: 0.527712984560702
### Intra sentences performance:
Validation Accuracy: 0.7440469946501626
Finished with this task.
###### (2) Training for configuration file: b-bert.ini
LOAD False
Using: cuda:0 with BERT
{'OVERLAP': 11844, 'BEFORE': 3137, 'O': 3475}
{'OVERLAP': 0.519419115163796, 'BEFORE': 1.961109340133886, 'O': 1.770359712230216}
Training Epoch: 0
Training loss epoch: 0.7836564779281616
Training accuracy epoch: 0.6272804054054054
Overall acc: 0.6263652527305055
Overall loss: 289.952880859375
Validation loss per 100 evaluation steps: 1.460440993309021
Validation loss per 100 evaluation steps: 1.10715648325363
Validation loss per 100 evaluation steps: 1.0909684140290787
Validation Loss: 1.0930699897018863
Validation Accuracy: 0.6457431457431457
Overall accuracy: 0.6459913326110509
Overall loss: 1.0930699897018863
Training Epoch: 1
Training loss epoch: 0.7553126215934753
Training accuracy epoch: 0.6381193693693693
Overall acc: 0.6380492760985522
Overall loss: 279.4656677246094
Validation loss per 100 evaluation steps: 0.7044011950492859
Validation loss per 100 evaluation steps: 0.924607518875953
Validation loss per 100 evaluation steps: 0.9664025185120046
Validation Loss: 0.970668350205277
Validation Accuracy: 0.6458333333333334
Overall accuracy: 0.6459913326110509
Overall loss: 0.970668350205277
Training Epoch: 2
Training loss epoch: 0.7575295567512512
Training accuracy epoch: 0.6381193693693693
Overall acc: 0.6380492760985522
Overall loss: 280.2859191894531
Validation loss per 100 evaluation steps: 1.1339099407196045
Validation loss per 100 evaluation steps: 0.9920626881689129
Validation loss per 100 evaluation steps: 0.9952878900131776
Validation Loss: 0.9933916750924412
Validation Accuracy: 0.6461940836940837
Overall accuracy: 0.6459913326110509
Overall loss: 0.9933916750924412
Training Epoch: 3
Training loss epoch: 0.7553811073303223
Training accuracy epoch: 0.6389358108108109
Overall acc: 0.6380492760985522
Overall loss: 279.4909973144531
Validation loss per 100 evaluation steps: 0.6466934680938721
Validation loss per 100 evaluation steps: 1.0531214086136016
Validation loss per 100 evaluation steps: 1.0247056911240762
Validation Loss: 1.0209393857361435
Validation Accuracy: 0.6460137085137084
Overall accuracy: 0.6459913326110509
Overall loss: 1.0209393857361435
Training Epoch: 4
Training loss epoch: 0.7562670111656189
Training accuracy epoch: 0.6389358108108109
Overall acc: 0.6380492760985522
Overall loss: 279.81878662109375
Validation loss per 100 evaluation steps: 1.736445426940918
Validation loss per 100 evaluation steps: 1.150456426167252
Validation loss per 100 evaluation steps: 1.1499770666236309
Validation Loss: 1.1596115951414232
Validation Accuracy: 0.6461940836940837
Overall accuracy: 0.6459913326110509
Overall loss: 1.1596115951414232
Training Epoch: 5
Training loss epoch: 0.7587316036224365
Training accuracy epoch: 0.6374436936936937
Overall acc: 0.6373719414105495
Overall loss: 280.7306823730469
Validation loss per 100 evaluation steps: 0.7068653106689453
Validation loss per 100 evaluation steps: 0.9722796439534367
Validation loss per 100 evaluation steps: 0.9971676970002663
Validation Loss: 0.9934651509765938
Validation Accuracy: 0.6461038961038961
Overall accuracy: 0.6459913326110509
Overall loss: 0.9934651509765938
Training Epoch: 6
Training loss epoch: 0.7580855488777161
Training accuracy epoch: 0.6381193693693693
Overall acc: 0.6380492760985522
Overall loss: 280.49163818359375
Validation loss per 100 evaluation steps: 0.9913638234138489
Validation loss per 100 evaluation steps: 0.9605321792682798
Validation loss per 100 evaluation steps: 0.9456400706696866
Validation Loss: 0.94851049497014
Validation Accuracy: 0.6456529581529582
Overall accuracy: 0.6459913326110509
Overall loss: 0.94851049497014
Training Epoch: 7
Training loss epoch: 0.7558808922767639
Training accuracy epoch: 0.6389358108108109
Overall acc: 0.6380492760985522
Overall loss: 279.6759338378906
Validation loss per 100 evaluation steps: 1.651060938835144
Validation loss per 100 evaluation steps: 0.9405809850385873
Validation loss per 100 evaluation steps: 0.965947635286483
Validation Loss: 0.971163485602383
Validation Accuracy: 0.6456529581529582
Overall accuracy: 0.6459913326110509
Overall loss: 0.971163485602383
Training Epoch: 8
Training loss epoch: 0.7575438022613525
Training accuracy epoch: 0.6364864864864865
Overall acc: 0.6380492760985522
Overall loss: 280.29119873046875
Validation loss per 100 evaluation steps: 0.6239906549453735
Validation loss per 100 evaluation steps: 0.9265606781043628
Validation loss per 100 evaluation steps: 0.9536335199923065
Validation Loss: 0.9511906304658749
Validation Accuracy: 0.6460137085137084
Overall accuracy: 0.6459913326110509
Overall loss: 0.9511906304658749
Training Epoch: 9
Training loss epoch: 0.7547000646591187
Training accuracy epoch: 0.6389358108108109
Overall acc: 0.6380492760985522
Overall loss: 279.239013671875
Validation loss per 100 evaluation steps: 1.239467978477478
Validation loss per 100 evaluation steps: 1.0575035308847334
Validation loss per 100 evaluation steps: 1.0407802830288067
Validation Loss: 1.0405601683633152
Validation Accuracy: 0.6461038961038961
Overall accuracy: 0.6459913326110509
Overall loss: 1.0405601683633152
Training Epoch: 10
Training loss epoch: 0.763959527015686
Training accuracy epoch: 0.633643018018018
Overall acc: 0.6335619337905343
Overall loss: 282.6650085449219
Validation loss per 100 evaluation steps: 0.7036916017532349
Validation loss per 100 evaluation steps: 0.9512006941408214
Validation loss per 100 evaluation steps: 0.950404397587278
Validation Loss: 0.9447257278801559
Validation Accuracy: 0.645923520923521
Overall accuracy: 0.6459913326110509
Overall loss: 0.9447257278801559
Training Epoch: 11
Training loss epoch: 0.7554616928100586
Training accuracy epoch: 0.6389358108108109
Overall acc: 0.6380492760985522
Overall loss: 279.52081298828125
Validation loss per 100 evaluation steps: 0.8391061425209045
Validation loss per 100 evaluation steps: 1.031005591449171
Validation loss per 100 evaluation steps: 1.0251154871425818
Validation Loss: 1.017431259026259
Validation Accuracy: 0.6461038961038961
Overall accuracy: 0.6459913326110509
Overall loss: 1.017431259026259
Early stopping
### Valid set performance:
Validation loss per 100 evaluation steps: 1.0120912790298462
Validation loss per 100 evaluation steps: 1.0151276166486267
Validation Loss: 1.004955318167403
Validation Accuracy: 0.6515015015015014
Overall accuracy: 0.6512021672875042
Overall loss: 1.004955318167403
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       490
           O       0.00      0.00      0.00       540
     OVERLAP       0.65      1.00      0.79      1923

    accuracy                           0.65      2953
   macro avg       0.22      0.33      0.26      2953
weighted avg       0.42      0.65      0.51      2953

### Test set performance:
Validation loss per 100 evaluation steps: 1.2387237548828125
Validation loss per 100 evaluation steps: 1.0321233269601766
Validation loss per 100 evaluation steps: 1.0205570671392317
Validation Loss: 1.0175149658799687
Validation Accuracy: 0.6461940836940837
Overall accuracy: 0.6459913326110509
Overall loss: 1.0175149658799687
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       628
           O       0.00      0.00      0.00       679
     OVERLAP       0.65      1.00      0.78      2385

    accuracy                           0.65      3692
   macro avg       0.22      0.33      0.26      3692
weighted avg       0.42      0.65      0.51      3692

Finished with this task.
###### (3) Training for configuration file: a-bilstm.ini
LOAD False
Using: cuda:0 with NN
{'OVERLAP': 11844, 'BEFORE': 3137, 'O': 3350}
{'OVERLAP': 0.5159011595181808, 'BEFORE': 1.9478270109446392, 'O': 1.8239800995024875}
{'learning_rate': 0.01, 'epochs': 100, 'batch_size': 32, 'valid_batch_size': 16, 'optimizer': 'adam', 'weight_decay': 0.0001, 'early_stopping_patience': 5, 'early_stopping_delta': 0.01, 'embedding_dim': 300, 'max_length': 128, 'shuffle': True, 'num_workers': 0, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'logging_strategy': 'epoch', 'tune': False}
Epoch 1
-------------------------------
Batch 0, Loss: 1.1261658668518066
Batch 100, Loss: 0.5300467014312744
Batch 200, Loss: 0.7427337169647217
Batch 300, Loss: 0.5591118335723877
Epoch 2
-------------------------------
Batch 0, Loss: 0.7681943774223328
Batch 100, Loss: 0.674177348613739
Batch 200, Loss: 0.7120693325996399
Batch 300, Loss: 0.6405096054077148
Epoch 3
-------------------------------
Batch 0, Loss: 0.6832981705665588
Batch 100, Loss: 0.7443509697914124
Batch 200, Loss: 0.8405873775482178
Batch 300, Loss: 0.6803432106971741
Epoch 4
-------------------------------
Batch 0, Loss: 0.7536745667457581
Batch 100, Loss: 0.7325259447097778
Batch 200, Loss: 0.7845684289932251
Batch 300, Loss: 0.6674972772598267
Epoch 5
-------------------------------
Batch 0, Loss: 0.6833565831184387
Batch 100, Loss: 0.6082794666290283
Batch 200, Loss: 0.6690779328346252
Batch 300, Loss: 0.6036509871482849
Epoch 6
-------------------------------
Batch 0, Loss: 0.5626563429832458
Batch 100, Loss: 0.8354141116142273
Batch 200, Loss: 0.6802747845649719
Batch 300, Loss: 0.5625232458114624
Epoch 7
-------------------------------
Batch 0, Loss: 0.5595895051956177
Batch 100, Loss: 0.5373415350914001
Batch 200, Loss: 0.5212804079055786
Batch 300, Loss: 0.9132600426673889
Epoch 8
-------------------------------
Batch 0, Loss: 0.6698422431945801
Batch 100, Loss: 0.6321041584014893
Batch 200, Loss: 0.5993447303771973
Batch 300, Loss: 0.38785767555236816
Epoch 9
-------------------------------
Batch 0, Loss: 0.6161773204803467
Batch 100, Loss: 0.6823766231536865
Batch 200, Loss: 0.6444849371910095
Batch 300, Loss: 0.71163409948349
Epoch 10
-------------------------------
Batch 0, Loss: 0.7283414602279663
Batch 100, Loss: 0.6219860315322876
Batch 200, Loss: 0.5578293800354004
Batch 300, Loss: 0.6727316975593567
Epoch 11
-------------------------------
Batch 0, Loss: 0.5893336534500122
Batch 100, Loss: 0.6495780944824219
Batch 200, Loss: 0.6729367971420288
Batch 300, Loss: 0.6715943813323975
Epoch 12
-------------------------------
Batch 0, Loss: 0.820809006690979
Batch 100, Loss: 0.6588716506958008
Batch 200, Loss: 0.6807915568351746
Batch 300, Loss: 0.4752700924873352
Epoch 13
-------------------------------
Batch 0, Loss: 0.7656899094581604
Batch 100, Loss: 0.6938741207122803
Batch 200, Loss: 0.6456056237220764
Batch 300, Loss: 0.5366891622543335
Early stopping
### Valid set performance:
Validation Accuracy: 0.6648482782134334
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       474
           O       0.51      0.18      0.27       518
     OVERLAP       0.68      0.96      0.79      1941

    accuracy                           0.66      2933
   macro avg       0.39      0.38      0.35      2933
weighted avg       0.54      0.66      0.57      2933

### Test set performance:
Validation Accuracy: 0.6645759476411235
### Summary
              precision    recall  f1-score   support

      BEFORE       0.00      0.00      0.00       623
           O       0.51      0.19      0.28       622
     OVERLAP       0.68      0.96      0.79      2422

    accuracy                           0.66      3667
   macro avg       0.40      0.38      0.36      3667
weighted avg       0.53      0.66      0.57      3667

### Inter sentences performance:
Validation Accuracy: 0.6237760626655915
### Intra sentences performance:
Validation Accuracy: 0.7319170984455958
Finished with this task.
Process finished!
