Spawning shell within /cluster/home/julievt/.cache/pypoetry/virtualenvs/master-project-118ajfdt-py3.12
Installing dependencies from lock file

No dependencies to install or update

Installing the current project: master-project (0.1.0)
##### Start training for TRE... ######
### Processing the files:
###### (0) Training for configuration file: c-bert-bilstm.ini
LOAD False
Using: cuda:0 with NN
{'BEFORE': 13827, 'OVERLAP': 4112, 'BEFOREOVERLAP': 491, 'AFTER': 1113}
{'BEFORE': 0.3533485210096189, 'OVERLAP': 1.188168774319066, 'BEFOREOVERLAP': 9.95061099796334, 'AFTER': 4.389712488769092}
Create sweep with ID: zg54gigm
Sweep URL: https://wandb.ai/julievt-ntnu/tre-dtr-c-Task.SEQUENCE-nn-model/sweeps/zg54gigm
{'batch_size': 32, 'early_stopping_delta': 0.01, 'early_stopping_patience': 3, 'embedding_dim': 32, 'epochs': 100, 'learning_rate': 0.0001, 'max_length': 64, 'num_workers': 0, 'optimizer': 'adam', 'shuffle': True, 'valid_batch_size': 16, 'weight_decay': 0}
Epoch 1
-------------------------------
Batch 0, Loss: 1.3295835256576538
Batch 100, Loss: 0.6974708437919617
Batch 200, Loss: 0.4439801871776581
Batch 300, Loss: 0.40556877851486206
Epoch 2
-------------------------------
Batch 0, Loss: 0.48885056376457214
Batch 100, Loss: 0.8662649989128113
Batch 200, Loss: 0.5253766775131226
Batch 300, Loss: 0.47692039608955383
Epoch 3
-------------------------------
Batch 0, Loss: 0.3208765387535095
Batch 100, Loss: 0.6385104656219482
Batch 200, Loss: 0.7728227376937866
Batch 300, Loss: 0.48201096057891846
Epoch 4
-------------------------------
Batch 0, Loss: 0.3746716380119324
Batch 100, Loss: 0.5154296159744263
Batch 200, Loss: 0.5803680419921875
Batch 300, Loss: 0.34850507974624634
Epoch 5
-------------------------------
Batch 0, Loss: 0.2951768636703491
Batch 100, Loss: 0.5455518960952759
Batch 200, Loss: 0.4122174382209778
Batch 300, Loss: 0.4190467298030853
Epoch 6
-------------------------------
Batch 0, Loss: 0.30119410157203674
Batch 100, Loss: 0.4972957968711853
Batch 200, Loss: 0.29072293639183044
Batch 300, Loss: 0.391810804605484
Epoch 7
-------------------------------
Batch 0, Loss: 0.1909673810005188
Batch 100, Loss: 0.18037447333335876
Batch 200, Loss: 0.4470103085041046
Batch 300, Loss: 0.1920875608921051
Epoch 8
-------------------------------
Batch 0, Loss: 0.34243419766426086
Batch 100, Loss: 0.45871415734291077
Batch 200, Loss: 0.13005606830120087
Batch 300, Loss: 0.2688137888908386
Epoch 9
-------------------------------
Batch 0, Loss: 0.3607727587223053
Batch 100, Loss: 0.39940914511680603
Batch 200, Loss: 0.20844222605228424
Batch 300, Loss: 0.24055713415145874
Epoch 10
-------------------------------
Batch 0, Loss: 0.1286022961139679
Batch 100, Loss: 0.29406824707984924
Batch 200, Loss: 0.19891436398029327
Batch 300, Loss: 0.32108062505722046
Early stopping
### Valid set performance:
Validation Accuracy: 0.7751838823153182
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       175
       BEFORE       0.94      0.83      0.88      2197
BEFOREOVERLAP       0.29      0.45      0.35        87
      OVERLAP       0.54      0.85      0.66       668

     accuracy                           0.78      3127
    macro avg       0.44      0.53      0.47      3127
 weighted avg       0.78      0.78      0.77      3127

### Summary
               precision    recall  f1-score   support

       BEFORE       0.94      0.83      0.88      2197
      OVERLAP       0.54      0.85      0.66       668
        AFTER       0.00      0.00      0.00       175
BEFOREOVERLAP       0.29      0.45      0.35        87

     accuracy                           0.78      3127
    macro avg       0.44      0.53      0.47      3127
 weighted avg       0.78      0.78      0.77      3127

### Test set performance:
Validation Accuracy: 0.7695062675876183
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       222
       BEFORE       0.94      0.82      0.88      2776
BEFOREOVERLAP       0.23      0.46      0.31        84
      OVERLAP       0.53      0.83      0.64       827

     accuracy                           0.77      3909
    macro avg       0.42      0.53      0.46      3909
 weighted avg       0.78      0.77      0.76      3909

### Summary
               precision    recall  f1-score   support

       BEFORE       0.94      0.82      0.88      2776
      OVERLAP       0.53      0.83      0.64       827
        AFTER       0.00      0.00      0.00       222
BEFOREOVERLAP       0.23      0.46      0.31        84

     accuracy                           0.77      3909
    macro avg       0.42      0.53      0.46      3909
 weighted avg       0.78      0.77      0.76      3909

{'batch_size': 32, 'early_stopping_delta': 0.01, 'early_stopping_patience': 3, 'embedding_dim': 32, 'epochs': 100, 'learning_rate': 0.0001, 'max_length': 64, 'num_workers': 0, 'optimizer': 'adam', 'shuffle': True, 'valid_batch_size': 16, 'weight_decay': 1e-05}
Epoch 1
-------------------------------
Batch 0, Loss: 1.3895992040634155
Batch 100, Loss: 0.5301825404167175
Batch 200, Loss: 0.736103355884552
Batch 300, Loss: 0.9153435230255127
Epoch 2
-------------------------------
Batch 0, Loss: 0.3628414273262024
Batch 100, Loss: 0.7066671252250671
Batch 200, Loss: 0.27296653389930725
Batch 300, Loss: 0.6559566259384155
Epoch 3
-------------------------------
Batch 0, Loss: 0.36589470505714417
Batch 100, Loss: 0.40191808342933655
Batch 200, Loss: 0.3554701805114746
Batch 300, Loss: 0.2519749104976654
Epoch 4
-------------------------------
Batch 0, Loss: 0.26800239086151123
Batch 100, Loss: 0.2953190207481384
Batch 200, Loss: 0.49520042538642883
Batch 300, Loss: 0.768375039100647
Epoch 5
-------------------------------
Batch 0, Loss: 0.19528041779994965
Batch 100, Loss: 0.13488224148750305
Batch 200, Loss: 0.1731480360031128
Batch 300, Loss: 0.6195483803749084
Epoch 6
-------------------------------
Batch 0, Loss: 0.16255855560302734
Batch 100, Loss: 0.1694377213716507
Batch 200, Loss: 0.45010247826576233
Batch 300, Loss: 0.19213812053203583
Epoch 7
-------------------------------
Batch 0, Loss: 0.22227229177951813
Batch 100, Loss: 0.29705148935317993
Batch 200, Loss: 0.428918719291687
Batch 300, Loss: 0.2027117758989334
Epoch 8
-------------------------------
Batch 0, Loss: 0.37113234400749207
Batch 100, Loss: 0.29022735357284546
Batch 200, Loss: 0.12472362816333771
Batch 300, Loss: 0.1379053145647049
Epoch 9
-------------------------------
Batch 0, Loss: 0.35645145177841187
Batch 100, Loss: 0.520362138748169
Batch 200, Loss: 0.10802286118268967
Batch 300, Loss: 0.11139381676912308
Epoch 10
-------------------------------
Batch 0, Loss: 0.0990818589925766
Batch 100, Loss: 0.10006483644247055
Batch 200, Loss: 0.15624259412288666
Batch 300, Loss: 0.3370826840400696
Epoch 11
-------------------------------
Batch 0, Loss: 0.06927375495433807
Batch 100, Loss: 0.10316658765077591
Batch 200, Loss: 0.17833057045936584
Batch 300, Loss: 0.043243102729320526
Epoch 12
-------------------------------
Batch 0, Loss: 0.19949272274971008
Batch 100, Loss: 0.04918380454182625
Batch 200, Loss: 0.12409576773643494
Batch 300, Loss: 0.05362922325730324
Epoch 13
-------------------------------
Batch 0, Loss: 0.5907301306724548
Batch 100, Loss: 0.14045026898384094
Batch 200, Loss: 0.18616782128810883
Batch 300, Loss: 0.03986648470163345
Early stopping
### Valid set performance:
Validation Accuracy: 0.8097217780620403
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.81      0.15      0.25       175
       BEFORE       0.90      0.90      0.90      2197
BEFOREOVERLAP       0.32      0.32      0.32        87
      OVERLAP       0.62      0.76      0.68       668

     accuracy                           0.81      3127
    macro avg       0.66      0.53      0.54      3127
 weighted avg       0.82      0.81      0.80      3127

### Summary
               precision    recall  f1-score   support

       BEFORE       0.90      0.90      0.90      2197
        AFTER       0.81      0.15      0.25       175
      OVERLAP       0.62      0.76      0.68       668
BEFOREOVERLAP       0.32      0.32      0.32        87

     accuracy                           0.81      3127
    macro avg       0.66      0.53      0.54      3127
 weighted avg       0.82      0.81      0.80      3127

### Test set performance:
Validation Accuracy: 0.8060885136863648
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.84      0.14      0.24       222
       BEFORE       0.91      0.89      0.90      2776
BEFOREOVERLAP       0.33      0.33      0.33        84
      OVERLAP       0.59      0.75      0.66       827

     accuracy                           0.81      3909
    macro avg       0.67      0.53      0.53      3909
 weighted avg       0.82      0.81      0.80      3909

### Summary
               precision    recall  f1-score   support

       BEFORE       0.91      0.89      0.90      2776
        AFTER       0.84      0.14      0.24       222
      OVERLAP       0.59      0.75      0.66       827
BEFOREOVERLAP       0.33      0.33      0.33        84

     accuracy                           0.81      3909
    macro avg       0.67      0.53      0.53      3909
 weighted avg       0.82      0.81      0.80      3909

{'batch_size': 32, 'early_stopping_delta': 0.01, 'early_stopping_patience': 3, 'embedding_dim': 32, 'epochs': 100, 'learning_rate': 0.0001, 'max_length': 64, 'num_workers': 0, 'optimizer': 'adam', 'shuffle': True, 'valid_batch_size': 16, 'weight_decay': 0.0001}
Epoch 1
-------------------------------
Batch 0, Loss: 1.4081780910491943
Batch 100, Loss: 0.5701035261154175
Batch 200, Loss: 0.40790143609046936
Batch 300, Loss: 0.7758392095565796
Epoch 2
-------------------------------
Batch 0, Loss: 0.8513971567153931
Batch 100, Loss: 0.4113418459892273
Batch 200, Loss: 0.37809139490127563
Batch 300, Loss: 0.5515689253807068
Epoch 3
-------------------------------
Batch 0, Loss: 0.5104546546936035
Batch 100, Loss: 0.40889865159988403
Batch 200, Loss: 0.5037500262260437
Batch 300, Loss: 0.24804699420928955
Epoch 4
-------------------------------
Batch 0, Loss: 0.27978864312171936
Batch 100, Loss: 0.1855236440896988
Batch 200, Loss: 0.25133708119392395
Batch 300, Loss: 0.21861249208450317
Epoch 5
-------------------------------
Batch 0, Loss: 0.5458776950836182
Batch 100, Loss: 0.39759647846221924
Batch 200, Loss: 0.39033567905426025
Batch 300, Loss: 0.3650049567222595
Epoch 6
-------------------------------
Batch 0, Loss: 0.5085797309875488
Batch 100, Loss: 0.17490477859973907
Batch 200, Loss: 0.418986052274704
Batch 300, Loss: 0.2830680310726166
Epoch 7
-------------------------------
Batch 0, Loss: 0.26847922801971436
Batch 100, Loss: 0.4087305963039398
Batch 200, Loss: 0.37465083599090576
Batch 300, Loss: 0.14995165169239044
Epoch 8
-------------------------------
Batch 0, Loss: 0.18926548957824707
Batch 100, Loss: 0.29341453313827515
Batch 200, Loss: 0.2908637821674347
Batch 300, Loss: 0.1443387120962143
Epoch 9
-------------------------------
Batch 0, Loss: 0.0996476486325264
Batch 100, Loss: 0.15096674859523773
Batch 200, Loss: 0.5638146996498108
Batch 300, Loss: 0.19448673725128174
Epoch 10
-------------------------------
Batch 0, Loss: 0.24667362868785858
Batch 100, Loss: 0.13029228150844574
Batch 200, Loss: 0.1158776804804802
Batch 300, Loss: 0.2925565540790558
Early stopping
### Valid set performance:
Validation Accuracy: 0.7847777422449632
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       175
       BEFORE       0.93      0.85      0.88      2197
BEFOREOVERLAP       0.42      0.13      0.19        87
      OVERLAP       0.53      0.87      0.66       668

     accuracy                           0.78      3127
    macro avg       0.47      0.46      0.44      3127
 weighted avg       0.78      0.78      0.77      3127

### Summary
               precision    recall  f1-score   support

       BEFORE       0.93      0.85      0.88      2197
      OVERLAP       0.53      0.87      0.66       668
        AFTER       0.00      0.00      0.00       175
BEFOREOVERLAP       0.42      0.13      0.19        87

     accuracy                           0.78      3127
    macro avg       0.47      0.46      0.44      3127
 weighted avg       0.78      0.78      0.77      3127

### Test set performance:
Validation Accuracy: 0.7784599641852136
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       1.00      0.00      0.01       222
       BEFORE       0.93      0.84      0.88      2776
BEFOREOVERLAP       0.34      0.17      0.22        84
      OVERLAP       0.52      0.85      0.64       827

     accuracy                           0.78      3909
    macro avg       0.70      0.46      0.44      3909
 weighted avg       0.83      0.78      0.77      3909

### Summary
               precision    recall  f1-score   support

       BEFORE       0.93      0.84      0.88      2776
        AFTER       1.00      0.00      0.01       222
      OVERLAP       0.52      0.85      0.64       827
BEFOREOVERLAP       0.34      0.17      0.22        84

     accuracy                           0.78      3909
    macro avg       0.70      0.46      0.44      3909
 weighted avg       0.83      0.78      0.77      3909

{'batch_size': 32, 'early_stopping_delta': 0.01, 'early_stopping_patience': 3, 'embedding_dim': 32, 'epochs': 100, 'learning_rate': 0.0001, 'max_length': 64, 'num_workers': 0, 'optimizer': 'adam', 'shuffle': True, 'valid_batch_size': 16, 'weight_decay': 0.001}
Epoch 1
-------------------------------
Batch 0, Loss: 1.400001883506775
Batch 100, Loss: 0.6856939196586609
Batch 200, Loss: 0.922842800617218
Batch 300, Loss: 0.6248627305030823
Epoch 2
-------------------------------
Batch 0, Loss: 0.5475394129753113
Batch 100, Loss: 0.3588082194328308
Batch 200, Loss: 0.6551290154457092
Batch 300, Loss: 0.6885921359062195
Epoch 3
-------------------------------
Batch 0, Loss: 0.4046899974346161
Batch 100, Loss: 0.6415786743164062
Batch 200, Loss: 0.46971195936203003
Batch 300, Loss: 0.8127194046974182
Epoch 4
-------------------------------
Batch 0, Loss: 0.5382744669914246
Batch 100, Loss: 0.41413190960884094
Batch 200, Loss: 0.6728570461273193
Batch 300, Loss: 0.49967724084854126
Epoch 5
-------------------------------
Batch 0, Loss: 0.4902544319629669
Batch 100, Loss: 0.31669604778289795
Batch 200, Loss: 0.24290965497493744
Batch 300, Loss: 0.4128866493701935
Epoch 6
-------------------------------
Batch 0, Loss: 0.17269515991210938
Batch 100, Loss: 0.4147862493991852
Batch 200, Loss: 0.3120320439338684
Batch 300, Loss: 0.3840688467025757
Epoch 7
-------------------------------
Batch 0, Loss: 0.1697520762681961
Batch 100, Loss: 0.5436570048332214
Batch 200, Loss: 0.13251259922981262
Batch 300, Loss: 0.37331220507621765
Epoch 8
-------------------------------
Batch 0, Loss: 0.5343376994132996
Batch 100, Loss: 0.14452926814556122
Batch 200, Loss: 0.26639702916145325
Batch 300, Loss: 0.13828951120376587
Epoch 9
-------------------------------
Batch 0, Loss: 0.3323565423488617
Batch 100, Loss: 0.29873189330101013
Batch 200, Loss: 0.20922958850860596
Batch 300, Loss: 0.23546157777309418
Epoch 10
-------------------------------
Batch 0, Loss: 0.1555110365152359
Batch 100, Loss: 0.13207009434700012
Batch 200, Loss: 0.19449397921562195
Batch 300, Loss: 0.3250395655632019
Early stopping
### Valid set performance:
Validation Accuracy: 0.7649504317236968
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       175
       BEFORE       0.91      0.83      0.87      2197
BEFOREOVERLAP       0.32      0.13      0.18        87
      OVERLAP       0.51      0.84      0.64       668

     accuracy                           0.76      3127
    macro avg       0.44      0.45      0.42      3127
 weighted avg       0.76      0.76      0.75      3127

### Summary
               precision    recall  f1-score   support

       BEFORE       0.91      0.83      0.87      2197
      OVERLAP       0.51      0.84      0.64       668
        AFTER       0.00      0.00      0.00       175
BEFOREOVERLAP       0.32      0.13      0.18        87

     accuracy                           0.76      3127
    macro avg       0.44      0.45      0.42      3127
 weighted avg       0.76      0.76      0.75      3127

### Test set performance:
Validation Accuracy: 0.7725761064210795
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       222
       BEFORE       0.92      0.84      0.87      2776
BEFOREOVERLAP       0.41      0.15      0.22        84
      OVERLAP       0.51      0.83      0.63       827

     accuracy                           0.77      3909
    macro avg       0.46      0.46      0.43      3909
 weighted avg       0.77      0.77      0.76      3909

### Summary
               precision    recall  f1-score   support

       BEFORE       0.92      0.84      0.87      2776
      OVERLAP       0.51      0.83      0.63       827
        AFTER       0.00      0.00      0.00       222
BEFOREOVERLAP       0.41      0.15      0.22        84

     accuracy                           0.77      3909
    macro avg       0.46      0.46      0.43      3909
 weighted avg       0.77      0.77      0.76      3909

{'batch_size': 32, 'early_stopping_delta': 0.01, 'early_stopping_patience': 3, 'embedding_dim': 32, 'epochs': 100, 'learning_rate': 0.0001, 'max_length': 64, 'num_workers': 0, 'optimizer': 'adam', 'shuffle': True, 'valid_batch_size': 16, 'weight_decay': 0.01}
Epoch 1
-------------------------------
Batch 0, Loss: 1.404117226600647
Batch 100, Loss: 0.44287213683128357
Batch 200, Loss: 0.7014195919036865
Batch 300, Loss: 0.6832678318023682
Epoch 2
-------------------------------
Batch 0, Loss: 0.6344648599624634
Batch 100, Loss: 0.5344382524490356
Batch 200, Loss: 0.3596329391002655
Batch 300, Loss: 0.40165483951568604
Epoch 3
-------------------------------
Batch 0, Loss: 0.5426591634750366
Batch 100, Loss: 0.5155035853385925
Batch 200, Loss: 0.448098361492157
Batch 300, Loss: 0.5341327786445618
Epoch 4
-------------------------------
Batch 0, Loss: 0.40990960597991943
Batch 100, Loss: 0.3405016362667084
Batch 200, Loss: 0.3807760179042816
Batch 300, Loss: 0.31645023822784424
Epoch 5
-------------------------------
Batch 0, Loss: 0.39525580406188965
Batch 100, Loss: 0.5472233295440674
Batch 200, Loss: 0.26872771978378296
Batch 300, Loss: 0.20114187896251678
Epoch 6
-------------------------------
Batch 0, Loss: 0.4588221609592438
Batch 100, Loss: 0.3209766149520874
Batch 200, Loss: 0.5889257788658142
Batch 300, Loss: 0.3818419277667999
Epoch 7
-------------------------------
Batch 0, Loss: 0.4377528429031372
Batch 100, Loss: 0.24464821815490723
Batch 200, Loss: 0.3342636823654175
Batch 300, Loss: 0.3276195526123047
Epoch 8
-------------------------------
Batch 0, Loss: 0.32864025235176086
Batch 100, Loss: 0.5518242120742798
Batch 200, Loss: 0.07219459116458893
Batch 300, Loss: 0.23695825040340424
Early stopping
### Valid set performance:
Validation Accuracy: 0.7659098177166613
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       175
       BEFORE       0.94      0.81      0.87      2197
BEFOREOVERLAP       0.32      0.32      0.32        87
      OVERLAP       0.51      0.88      0.65       668

     accuracy                           0.77      3127
    macro avg       0.44      0.50      0.46      3127
 weighted avg       0.78      0.77      0.76      3127

### Summary
               precision    recall  f1-score   support

       BEFORE       0.94      0.81      0.87      2197
      OVERLAP       0.51      0.88      0.65       668
        AFTER       0.00      0.00      0.00       175
BEFOREOVERLAP       0.32      0.32      0.32        87

     accuracy                           0.77      3127
    macro avg       0.44      0.50      0.46      3127
 weighted avg       0.78      0.77      0.76      3127

### Test set performance:
Validation Accuracy: 0.7656689690457917
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.00      0.00      0.00       222
       BEFORE       0.94      0.81      0.87      2776
BEFOREOVERLAP       0.32      0.32      0.32        84
      OVERLAP       0.50      0.87      0.64       827

     accuracy                           0.77      3909
    macro avg       0.44      0.50      0.46      3909
 weighted avg       0.78      0.77      0.76      3909

### Summary
               precision    recall  f1-score   support

       BEFORE       0.94      0.81      0.87      2776
      OVERLAP       0.50      0.87      0.64       827
        AFTER       0.00      0.00      0.00       222
BEFOREOVERLAP       0.32      0.32      0.32        84

     accuracy                           0.77      3909
    macro avg       0.44      0.50      0.46      3909
 weighted avg       0.78      0.77      0.76      3909

Finished with this task.
###### (2) Training for configuration file: b-bert.ini
LOAD False
Using: cuda:0 with BERT
Create sweep with ID: kbwju2bk
Sweep URL: https://wandb.ai/julievt-ntnu/tre-dtr-b-Task.SEQUENCE-bert-model/sweeps/kbwju2bk
{'BEFORE': 24490, 'OVERLAP': 6544, 'BEFOREOVERLAP': 804, 'AFTER': 1744}
{'BEFORE': 0.34281339322172316, 'OVERLAP': 1.2829309290953546, 'BEFOREOVERLAP': 10.442164179104477, 'AFTER': 4.813933486238532}
Training Epoch: 0
Training loss epoch: 0.5513144731521606
Training accuracy epoch: 0.6425316220238095
Overall acc: 0.6424716173459892
Overall loss: 370.48333740234375
Validation loss per 100 evaluation steps: 1.0739281177520752
Validation loss per 100 evaluation steps: 1.0339443952140241
Validation loss per 100 evaluation steps: 1.0067710492444868
Validation loss per 100 evaluation steps: 1.0120318278521794
Validation loss per 100 evaluation steps: 1.0196618639545845
Validation Loss: 1.0095278816918531
Validation Accuracy: 0.648489010989011
Overall accuracy: 0.6485037963376508
Overall loss: 1.0095278816918531
Training Epoch: 1
Training loss epoch: 0.44757604598999023
Training accuracy epoch: 0.7297247023809523
Overall acc: 0.7297133817234319
Overall loss: 300.7710876464844
Validation loss per 100 evaluation steps: 0.7043063044548035
Validation loss per 100 evaluation steps: 0.8705626534353389
Validation loss per 100 evaluation steps: 0.8439550406452435
Validation loss per 100 evaluation steps: 0.8419852321627133
Validation loss per 100 evaluation steps: 0.842939743042884
Validation Loss: 0.8411583958282357
Validation Accuracy: 0.6948031135531135
Overall accuracy: 0.694804228078011
Overall loss: 0.8411583958282357
Training Epoch: 2
Training loss epoch: 0.3686057925224304
Training accuracy epoch: 0.7787388392857143
Overall acc: 0.7787548855388051
Overall loss: 247.7030792236328
Validation loss per 100 evaluation steps: 1.304556965827942
Validation loss per 100 evaluation steps: 0.8572437971609064
Validation loss per 100 evaluation steps: 0.8815606470168823
Validation loss per 100 evaluation steps: 0.8919056962519587
Validation loss per 100 evaluation steps: 0.8600492222220671
Validation Loss: 0.8627561292211924
Validation Accuracy: 0.7028044871794873
Overall accuracy: 0.7028435313383952
Overall loss: 0.8627561292211924
Training Epoch: 3
Training loss epoch: 0.3000873923301697
Training accuracy epoch: 0.8145275297619047
Overall acc: 0.814535641168807
Overall loss: 201.65872192382812
Validation loss per 100 evaluation steps: 0.7527386546134949
Validation loss per 100 evaluation steps: 0.7230419414025722
Validation loss per 100 evaluation steps: 0.685315750353965
Validation loss per 100 evaluation steps: 0.704725597536445
Validation loss per 100 evaluation steps: 0.7130170894456921
Validation Loss: 0.7173031125395071
Validation Accuracy: 0.7632898351648352
Overall accuracy: 0.7632871817775793
Overall loss: 0.7173031125395071
Training Epoch: 4
Training loss epoch: 0.247717946767807
Training accuracy epoch: 0.8397321428571428
Overall acc: 0.8397543271915131
Overall loss: 166.46646118164062
Validation loss per 100 evaluation steps: 0.4019319713115692
Validation loss per 100 evaluation steps: 0.7341039273703452
Validation loss per 100 evaluation steps: 0.736211314834469
Validation loss per 100 evaluation steps: 0.7332772958120238
Validation loss per 100 evaluation steps: 0.719899171345549
Validation Loss: 0.7188962821094763
Validation Accuracy: 0.7572687728937729
Overall accuracy: 0.7573321423254429
Overall loss: 0.7188962821094763
Training Epoch: 5
Training loss epoch: 0.19757547974586487
Training accuracy epoch: 0.86640625
Overall acc: 0.8664154103852596
Overall loss: 132.77072143554688
Validation loss per 100 evaluation steps: 0.20899739861488342
Validation loss per 100 evaluation steps: 0.6284093997708642
Validation loss per 100 evaluation steps: 0.6501663872295648
Validation loss per 100 evaluation steps: 0.6565033753968751
Validation loss per 100 evaluation steps: 0.6597949769301457
Validation Loss: 0.6558083023787254
Validation Accuracy: 0.7846382783882784
Overall accuracy: 0.7845764478189668
Overall loss: 0.6558083023787254
Training Epoch: 6
Training loss epoch: 0.1718282252550125
Training accuracy epoch: 0.8852120535714285
Overall acc: 0.8852596314907872
Overall loss: 115.46856689453125
Validation loss per 100 evaluation steps: 0.6613534688949585
Validation loss per 100 evaluation steps: 0.7793087785012356
Validation loss per 100 evaluation steps: 0.7718528515719507
Validation loss per 100 evaluation steps: 0.7836243567796443
Validation loss per 100 evaluation steps: 0.7861049697267593
Validation Loss: 0.7888778105466848
Validation Accuracy: 0.7607600732600732
Overall accuracy: 0.7607562900104213
Overall loss: 0.7888778105466848
Training Epoch: 7
Training loss epoch: 0.12665104866027832
Training accuracy epoch: 0.9109561011904762
Overall acc: 0.9109901358645077
Overall loss: 85.10950469970703
Validation loss per 100 evaluation steps: 0.25546810030937195
Validation loss per 100 evaluation steps: 0.794547409630648
Validation loss per 100 evaluation steps: 0.7728283103712978
Validation loss per 100 evaluation steps: 0.7568662948875481
Validation loss per 100 evaluation steps: 0.7649113799589327
Validation Loss: 0.7658710304880515
Validation Accuracy: 0.8069253663003664
Overall accuracy: 0.8069078457644782
Overall loss: 0.7658710304880515
Training Epoch: 8
Training loss epoch: 0.10842827707529068
Training accuracy epoch: 0.9266555059523809
Overall acc: 0.9266703889819468
Overall loss: 72.86380004882812
Validation loss per 100 evaluation steps: 1.4495799541473389
Validation loss per 100 evaluation steps: 0.9347441537849752
Validation loss per 100 evaluation steps: 0.9616215762830529
Validation loss per 100 evaluation steps: 0.9704172083028156
Validation loss per 100 evaluation steps: 0.978323080213485
Validation Loss: 0.9746984584378966
Validation Accuracy: 0.759569597069597
Overall accuracy: 0.7595652821199941
Overall loss: 0.9746984584378966
Early stopping
### Valid set performance:
Validation loss per 100 evaluation steps: 1.099705696105957
Validation loss per 100 evaluation steps: 0.925900255339128
Validation loss per 100 evaluation steps: 0.9272815624891377
Validation loss per 100 evaluation steps: 0.9297375990715236
Validation Loss: 0.9365635781072169
Validation Accuracy: 0.7660971840659341
Overall accuracy: 0.7660524846454495
Overall loss: 0.9365635781072169
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.87      0.05      0.09       284
       BEFORE       0.96      0.80      0.87      3870
BEFOREOVERLAP       0.45      0.25      0.32       140
      OVERLAP       0.48      0.91      0.63      1079

     accuracy                           0.77      5373
    macro avg       0.69      0.50      0.48      5373
 weighted avg       0.84      0.77      0.77      5373

### Summary
               precision    recall  f1-score   support

       BEFORE       0.96      0.80      0.87      3870
        AFTER       0.87      0.05      0.09       284
      OVERLAP       0.48      0.91      0.63      1079
BEFOREOVERLAP       0.45      0.25      0.32       140

     accuracy                           0.77      5373
    macro avg       0.69      0.50      0.48      5373
 weighted avg       0.84      0.77      0.77      5373

### Test set performance:
Validation loss per 100 evaluation steps: 1.0355017185211182
Validation loss per 100 evaluation steps: 0.9555355275031363
Validation loss per 100 evaluation steps: 0.9690335597958768
Validation loss per 100 evaluation steps: 0.953796757071084
Validation loss per 100 evaluation steps: 0.9812961027520869
Validation Loss: 0.9744849201480281
Validation Accuracy: 0.7596039377289378
Overall accuracy: 0.7595652821199941
Overall loss: 0.9744849201480281
### BIO-Scheme
               precision    recall  f1-score   support

        AFTER       0.89      0.05      0.09       363
       BEFORE       0.95      0.79      0.86      4877
BEFOREOVERLAP       0.45      0.24      0.31       160
      OVERLAP       0.46      0.89      0.61      1317

     accuracy                           0.76      6717
    macro avg       0.69      0.49      0.47      6717
 weighted avg       0.84      0.76      0.76      6717

### Summary
               precision    recall  f1-score   support

       BEFORE       0.95      0.79      0.86      4877
        AFTER       0.89      0.05      0.09       363
      OVERLAP       0.46      0.89      0.61      1317
BEFOREOVERLAP       0.45      0.24      0.31       160

     accuracy                           0.76      6717
    macro avg       0.69      0.49      0.47      6717
 weighted avg       0.84      0.76      0.76      6717

{'BEFORE': 24490, 'OVERLAP': 6544, 'BEFOREOVERLAP': 804, 'AFTER': 1744}
{'BEFORE': 0.34281339322172316, 'OVERLAP': 1.2829309290953546, 'BEFOREOVERLAP': 10.442164179104477, 'AFTER': 4.813933486238532}
Training Epoch: 0
Training loss epoch: 0.5546254515647888
Training accuracy epoch: 0.6439546130952382
Overall acc: 0.6438674855760282
Overall loss: 372.7082824707031
Validation loss per 100 evaluation steps: 0.3478315770626068
Validation loss per 100 evaluation steps: 0.8560576255958859
Validation loss per 100 evaluation steps: 0.8608676368620858
Validation loss per 100 evaluation steps: 0.8534556075782079
Validation loss per 100 evaluation steps: 0.8683571233936676
Validation Loss: 0.8656300983613445
Validation Accuracy: 0.6580471611721611
Overall accuracy: 0.6580318594610689
Overall loss: 0.8656300983613445
Training Epoch: 1
